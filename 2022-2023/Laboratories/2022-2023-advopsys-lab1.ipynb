{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Operating Systems: Lab 1 - Getting Started with Kernel Tracing\n",
    "\n",
    "This first lab, worth only 10% of your overall marks, is to teach some baseline skills in using DTrace and Jupyter to do OS tracing, analysis, and data presentation. You are encouraged to explore the assignment using this Notebook, but create a new Notebook with only the assigned work to submit a clean version for marking. Please submit a generated PDF of the Notebook, which may be done using File->Print and your web browser/OS's PDF export functionality.\n",
    "\n",
    "Start by working through the teaching activities below, exploring how DTrace and Python interact to allow us to capture and process trace data to understand a simple workload. Then create a new Notebook to answer the specific exercises at the bottom of this Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Running and tracing the workload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these exercises, we will use the UNIX `dd(1)` command used in examples during lecture.  dd copies data from `stdin` to `stdout` in fixed size blocks.  We will use a simple invocation that copies zeros from `/dev/zero` into the null device, `/dev/null`, with a block size of 1KiB in quantity 10000.\n",
    "\n",
    "`dd if=/dev/zero of=/dev/null bs=1k count=10000`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running dd(1) from Jupyter\n",
    "\n",
    "We can use Jupyter's `!` syntax to run UNIX commands; we will run it without `status=none` so that a message is printed when it completes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dd if=/dev/zero of=/dev/null bs=1k count=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the dtrace(1) command-line tool from Jupyter\n",
    "\n",
    "We can use the DTrace command-line tool via the same syntax. This example counts system calls when running our `dd(1)` command. Note that we use `execname` to filter probe firings even though `-s` is specified, in order to avoid tracing concurrent system activity, including from DTrace and Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dtrace -n 'syscall:::entry /execname == \"dd\"/ { @syscalls[probefunc] = count(); }' -c 'dd if=/dev/zero of=/dev/null bs=1k count=10000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Capturing DTrace output in Python\n",
    "\n",
    "To better analyse and present DTrace output, we use the `python-dtrace` module to run DTrace and capture its output directly to Python data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##Â Import the DTrace module\n",
    "\n",
    "First import the `python-dtrace` module. This must be done once per session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtrace import DTraceConsumerThread\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a DTrace convenience function\n",
    "\n",
    "Next, abstract a little away from the mechanics of the DTrace module. Callers will need to provide a D script, a \"walker\" function to handle data inputs, and a command line to execute. This must be done once per session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtrace_synchronous(script, walker, cmdline):\n",
    "    \"\"\"\n",
    "    script - D script\n",
    "    walker - Walker routine to receive data\n",
    "    cmdline - Command to run\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a seperate thread to run the DTrace instrumentation\n",
    "    dtrace_thread = DTraceConsumerThread(script,\n",
    "                                     walk_func=walker,\n",
    "                                     out_func=lambda v: None,\n",
    "                                     chew_func=lambda v: None,\n",
    "                                     chewrec_func=lambda v: None,\n",
    "                                     sleep=1)\n",
    "    \n",
    "    # Start the DTrace instrumentation\n",
    "    dtrace_thread.start()\n",
    "\n",
    "    # Display header to indicate that dd(1) has started\n",
    "    print(\"## Starting \", cmdline)\n",
    "\n",
    "    output_dtrace = subprocess.run(cmdline.split(\" \"))\n",
    "        \n",
    "    # The benchmark has completed - stop the DTrace instrumentation\n",
    "    dtrace_thread.stop()\n",
    "    dtrace_thread.join()\n",
    "\n",
    "    # Display footer to indicate that the benchmarking has finished\n",
    "    print(\"## Finished \", cmdline)\n",
    "    \n",
    "    # Explicitly free DTrace resources.\n",
    "    # Python's Garbage Collector would free DTrace resources when\n",
    "    # dtrace_thread is reassigned, e.g. when the cell is reexecuted.\n",
    "    # This could be confusing when analysing kernel from a terminal\n",
    "    # and the notebook at the same time.\n",
    "    del dtrace_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect system-call counts\n",
    "\n",
    "We run the same script as above, counting system calls by name, only this time capture the data using the `python-dtrace` module directly into Python data structures.  Keys passed to `syscall_count_walker` are system-call names, and values are counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample D-language script embedded in a Python string.\n",
    "syscall_count_script = \"\"\"\n",
    "syscall:::entry /execname == \"dd\"/ { @syscalls[probefunc] = count(); }\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "syscall_count_values = defaultdict(int)\n",
    "    \n",
    "def syscall_count_walker(action, identifier, keys, value):\n",
    "    \"\"\"\n",
    "    action -- type of action (sum, avg, ...)\n",
    "    identifier -- the id.\n",
    "    keys -- list of keys.\n",
    "    value -- the value.\n",
    "    \"\"\"\n",
    "    syscall_count_values[keys[0]] += value\n",
    "\n",
    "# Run it all under DTrace\n",
    "dtrace_synchronous(syscall_count_script, syscall_count_walker, \"dd if=/dev/zero of=/dev/null bs=1k count=10000\")\n",
    "\n",
    "# Print the syscalls and their frequency\n",
    "for x in syscall_count_values.keys():\n",
    "    print(\"Number of \", x, \" calls: \", syscall_count_values[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach can be used to extract a variety of kernel trace data using DTrace. One known limitation is that stack() results are stored as a set of code addresses, rather than being expanded to strings, so you will likely prefer to use the `dtrace(1)` command-line tool to capture stack data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting a system-call count histogram\n",
    "\n",
    "Results from `python-dtrace` can be (relatively) easily plotted using Python's standard plotting modules, such as `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "labels = syscall_count_values.keys()\n",
    "values = syscall_count_values.values()\n",
    "\n",
    "y_pos = np.arange(len(labels))\n",
    "fig, ax = plt.subplots()\n",
    "hbars = ax.barh(y_pos, values)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(labels)\n",
    "ax.invert_yaxis()\n",
    "ax.bar_label(hbars, fmt='%d')\n",
    "ax.set_xlabel('Score')\n",
    "ax.set_title('Bar plot')\n",
    "fig.set_size_inches(12,6)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect timer-driven profiling data\n",
    "\n",
    "Now we repeat the same `dd(1)` workload, but with timer-driving profiling using DTrace's `profile-4997` probe.  In the prior script, keys were simple scalars. Now they are arrays containing stack frames. Values continue to contain counts.\n",
    "\n",
    "It is possible that you will see an empty key; this occurs when the profiling probe fires while code is executing in userspace, and so there is no current kernel stack trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample D-language script embedded in a Python string.\n",
    "profile_script = \"\"\"\n",
    "profile:::profile-4997 /execname == \"dd\"/ { @traces[stack()] = count(); }\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "profile_values = defaultdict(int)\n",
    "\n",
    "def profile_walker(action, identifier, keys, value):\n",
    "    \"\"\"\n",
    "    action -- type of action (sum, avg, ...)\n",
    "    identifier -- the id.\n",
    "    keys -- list of keys.\n",
    "    value -- the value.\n",
    "    \"\"\"\n",
    "    print(keys, value)\n",
    "    # We have to create a tuple because lists are not hashable\n",
    "    hashable_key = tuple(keys)\n",
    "    if keys == []:\n",
    "        hashable_key = tuple([\"userspace\"])\n",
    "    profile_values[hashable_key] += value\n",
    "\n",
    "# Run it all under DTrace\n",
    "dtrace_synchronous(profile_script, profile_walker, \"dd if=/dev/zero of=/dev/null bs=1k count=10000\")\n",
    "\n",
    "# Print the stack traces and their frequency\n",
    "for x in profile_values.keys():\n",
    "    print(f'Number of {x} calls: {profile_values[x]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a flame graph\n",
    "\n",
    "For backtrace data derived from profiling, a flamegraph can be invaluable.\n",
    "The original flamegraph implementation is in Perl, but we have a subset available via a new `pyflamegraph` module developed locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyflamegraph\n",
    "\n",
    "trace = pyflamegraph.TraceElement.from_pydtrace_dict(profile_values)\n",
    "\n",
    "stack_tree = pyflamegraph.StackTree.from_trace(trace)\n",
    "\n",
    "# Some sample transformations you can do\n",
    "# stack_tree = stack_tree.filter(lambda s: s.num_points > 2)\n",
    "# stack_tree = stack_tree.zoom(\"sys_read\")\n",
    "\n",
    "# You can also print the StackTree for a text-based analysis\n",
    "# print(stack_tree)\n",
    "\n",
    "flame_graph = pyflamegraph.Flamegraph.from_stack_tree(stack_tree)\n",
    "\n",
    "# Copied from https://stackoverflow.com/a/36368116/11751242 to make plot larger\n",
    "# You'll almost certainly have to mess with this on other monitors\n",
    "fig, ax = plt.subplots(\n",
    "    figsize=(16,8), \n",
    "    dpi= 200,\n",
    ")\n",
    "\n",
    "flame_graph.plot(fig, ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
